# general
gpu_id: 0 #0
use_gpu: True
seed: 19971003
state: INFO
dataset: preprocessed
num_samples: all  # 500
reproducibility: True
mode: train

# dataset
data_dir: '../Chinese_preprocess' #'../data'
node_vocab: '../preprocess/node.pkl'
relation_vocab: '../preprocess/relation.pkl'
node_embedding: '../preprocess/node_embeddings.npy'

# model
teacher_dir: "uer/t5-small-chinese-cluecorpussmall" #"bert-base-chinese" #"hfl/chinese-xlnet-base" #
plm_dir: "uer/t5-small-chinese-cluecorpussmall" #"bert-base-chinese" #"hfl/chinese-xlnet-base" #
log_dir: '../logging'

# training settings
start_epoch: 0
epochs: 400
train_batch_size: 16 #20
plm_learner: adamw
plm_lr: 0.000001
external_learner: adamw
external_lr: 0.00001
rec_weight: 1.0
kd_weight: 1.0
cp_weight: 0.5
gnn_layers: 2
embedding_size: 512 #1024
hidden_size: 512

# evaluation settings
eval_batch_size: 20

# testing settings
external_model: '../ckpt/webnlg-all-399/external.bin'
fine_tuned_plm_dir: '../ckpt/webnlg-all-399'
test_batch_size: 20
max_seq_length: 100
output_dir: '../ckpt/webnlg-all-399'
